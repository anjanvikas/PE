{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport copy\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch,torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets,models,transforms\nimport torch.optim as optim\n# from torchsummary import summary\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom torch.nn import Parameter\nfrom pathlib import Path\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:36.260729Z","iopub.execute_input":"2021-09-15T10:10:36.261308Z","iopub.status.idle":"2021-09-15T10:10:41.95942Z","shell.execute_reply.started":"2021-09-15T10:10:36.261221Z","shell.execute_reply":"2021-09-15T10:10:41.958683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path='../input/whole-model/k_cross_CNN.pt'","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:41.960828Z","iopub.execute_input":"2021-09-15T10:10:41.961079Z","iopub.status.idle":"2021-09-15T10:10:41.96531Z","shell.execute_reply.started":"2021-09-15T10:10:41.961037Z","shell.execute_reply":"2021-09-15T10:10:41.96463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load train, val, test csv files","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/covidxct/train_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntrain_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\n\n# 读取test.txt\nval_df = pd.read_csv('../input/covidxct/val_COVIDx_CT-2A.txt', sep=\" \", header=None)\nval_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\n\ntest_df = pd.read_csv('../input/covidxct/test_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntest_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:41.966343Z","iopub.execute_input":"2021-09-15T10:10:41.967476Z","iopub.status.idle":"2021-09-15T10:10:42.257579Z","shell.execute_reply.started":"2021-09-15T10:10:41.96744Z","shell.execute_reply":"2021-09-15T10:10:42.25673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()\ntrain_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.260632Z","iopub.execute_input":"2021-09-15T10:10:42.260975Z","iopub.status.idle":"2021-09-15T10:10:42.279717Z","shell.execute_reply.started":"2021-09-15T10:10:42.260944Z","shell.execute_reply":"2021-09-15T10:10:42.279061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/covidxct/2A_images/'  #directory path\ntrain_df['filename'] = image_path+train_df['filename']\nval_df['filename'] = image_path+val_df['filename']\ntest_df['filename'] = image_path + test_df['filename']\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.280988Z","iopub.execute_input":"2021-09-15T10:10:42.281309Z","iopub.status.idle":"2021-09-15T10:10:42.346792Z","shell.execute_reply.started":"2021-09-15T10:10:42.281274Z","shell.execute_reply":"2021-09-15T10:10:42.346081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Leaving pneumonia data","metadata":{}},{"cell_type":"code","source":"train_df = train_df[train_df['label']!=1]\nval_df = val_df[val_df['label']!=1]\ntest_df = test_df[test_df['label']!=1]","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.348073Z","iopub.execute_input":"2021-09-15T10:10:42.348343Z","iopub.status.idle":"2021-09-15T10:10:42.366472Z","shell.execute_reply.started":"2021-09-15T10:10:42.348314Z","shell.execute_reply":"2021-09-15T10:10:42.365813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['label']=train_df['label'].replace(2,1)\nval_df['label']=val_df['label'].replace(2,1)\ntest_df['label']=test_df['label'].replace(2,1)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.367851Z","iopub.execute_input":"2021-09-15T10:10:42.368122Z","iopub.status.idle":"2021-09-15T10:10:42.375702Z","shell.execute_reply.started":"2021-09-15T10:10:42.368086Z","shell.execute_reply":"2021-09-15T10:10:42.374962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.377111Z","iopub.execute_input":"2021-09-15T10:10:42.377438Z","iopub.status.idle":"2021-09-15T10:10:42.386631Z","shell.execute_reply.started":"2021-09-15T10:10:42.377404Z","shell.execute_reply":"2021-09-15T10:10:42.3857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = shuffle(train_df) # 打乱顺序\nval_df = shuffle(val_df)\ntest_df = shuffle(test_df)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.388025Z","iopub.execute_input":"2021-09-15T10:10:42.388316Z","iopub.status.idle":"2021-09-15T10:10:42.419557Z","shell.execute_reply.started":"2021-09-15T10:10:42.388282Z","shell.execute_reply":"2021-09-15T10:10:42.418784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels={0:'Normal',1:'COVID-19'}\nclass_names=['Normal','COVID-19']\n\ntrain_df['label_n']=[labels[b] for b in train_df['label']]\nval_df['label_n']=[labels[b] for b in val_df['label']]\ntest_df['label_n']=[labels[b] for b in test_df['label']]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.422448Z","iopub.execute_input":"2021-09-15T10:10:42.422638Z","iopub.status.idle":"2021-09-15T10:10:42.473649Z","shell.execute_reply.started":"2021-09-15T10:10:42.422615Z","shell.execute_reply":"2021-09-15T10:10:42.473051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Normal and Covid-19 values of train: \\n{train_df['label_n'].value_counts()}\")\nprint(f\"Normal and Covid-19 values of validation: \\n{val_df['label_n'].value_counts()}\")\nprint(f\"Normal and Covid-19 values of test: \\n{test_df['label_n'].value_counts()}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.474715Z","iopub.execute_input":"2021-09-15T10:10:42.474945Z","iopub.status.idle":"2021-09-15T10:10:42.513891Z","shell.execute_reply.started":"2021-09-15T10:10:42.474914Z","shell.execute_reply":"2021-09-15T10:10:42.513231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.515174Z","iopub.execute_input":"2021-09-15T10:10:42.515413Z","iopub.status.idle":"2021-09-15T10:10:42.526005Z","shell.execute_reply.started":"2021-09-15T10:10:42.515382Z","shell.execute_reply":"2021-09-15T10:10:42.525237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=train_df.reset_index()\nval_df=val_df.reset_index()\ntest_df=test_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.527539Z","iopub.execute_input":"2021-09-15T10:10:42.527794Z","iopub.status.idle":"2021-09-15T10:10:42.542792Z","shell.execute_reply.started":"2021-09-15T10:10:42.527762Z","shell.execute_reply":"2021-09-15T10:10:42.54219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CovidDataset(Dataset):\n    def __init__(self, dataset_df, transform=None):\n        self.dataset_df = dataset_df\n        self.transform = transform\n        \n    def __len__(self):\n        return self.dataset_df.shape[0]\n    \n    def __getitem__(self, idx):\n        image_name = self.dataset_df['filename'][idx]\n        xmin,ymin,xmax,ymax=self.dataset_df['xmin'][idx],self.dataset_df['ymin'][idx],self.dataset_df['xmax'][idx],self.dataset_df['ymax'][idx]\n        img = cv2.imread(image_name)\n        img = img[ymin:ymax, xmin:xmax, :]\n        img=transforms.ToTensor()(img)\n        img=transforms.ToPILImage()(img)\n        label = self.dataset_df['label'][idx]\n        \n        if self.transform:\n            img = self.transform(img)\n        return img, label\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.543957Z","iopub.execute_input":"2021-09-15T10:10:42.544225Z","iopub.status.idle":"2021-09-15T10:10:42.551828Z","shell.execute_reply.started":"2021-09-15T10:10:42.544193Z","shell.execute_reply":"2021-09-15T10:10:42.550961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\ninput_channel = 3\ninput_size = (224,224)\nnum_classes=2\nnum_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.553454Z","iopub.execute_input":"2021-09-15T10:10:42.553749Z","iopub.status.idle":"2021-09-15T10:10:42.560522Z","shell.execute_reply.started":"2021-09-15T10:10:42.553715Z","shell.execute_reply":"2021-09-15T10:10:42.559696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = {\n    'train':transforms.Compose([\n\n#         transforms.CenterCrop(crop_size),\n        transforms.Resize(input_size),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomRotation(30),\n        transforms.ToTensor(),\n#         transforms.Normalize([0.6349431],[0.32605055])\n#         transforms.Grayscale(input_channel),\n\n    ]),\n    'test':transforms.Compose([\n#         transforms.CenterCrop(crop_size),\n        transforms.Resize(input_size),\n        transforms.ToTensor(),\n#         transforms.Normalize([0.63507175],[0.3278614])\n#         transforms.Grayscale(input_channel),\n\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.561914Z","iopub.execute_input":"2021-09-15T10:10:42.562244Z","iopub.status.idle":"2021-09-15T10:10:42.56905Z","shell.execute_reply.started":"2021-09-15T10:10:42.562212Z","shell.execute_reply":"2021-09-15T10:10:42.568086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_names=['train','val','test']\nimage_transforms = {'train':transform['train'], 'val':transform['test'],'test':transform['test']}\n\ntrain_dataset = CovidDataset(train_df, transform=image_transforms['train'])\nval_dataset = CovidDataset(val_df, transform=image_transforms['test'])\ntest_dataset = CovidDataset(test_df, transform=image_transforms['test'])\n\nimage_dataset = {'train':train_dataset, 'val':val_dataset,'test':test_dataset}\n\ndataloaders = {x:DataLoader(image_dataset[x],batch_size=batch_size,shuffle=True,num_workers=8) for x in dataset_names}\n\ndataset_sizes = {x:len(image_dataset[x]) for x in dataset_names}","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.57024Z","iopub.execute_input":"2021-09-15T10:10:42.570743Z","iopub.status.idle":"2021-09-15T10:10:42.580135Z","shell.execute_reply.started":"2021-09-15T10:10:42.570674Z","shell.execute_reply":"2021-09-15T10:10:42.579418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\ndef show_tensor_img(tensor_img):\n#     to_pil = transforms.ToPILImage()\n#     img = tensor_img.cpu().clone()\n#     img = to_pil(img)\n    img=transforms.ToPILImage()(tensor_img)\n    plt.figure()\n    plt.imshow(img,plt.cm.gray)\n    plt.show()\n\ndef show_img(idx):\n  show_tensor_img(train_dataset[(train_df[train_df['label']==(idx%2)].index)[idx]][0])\nfor i in range(4):\n    show_img(i)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:42.583389Z","iopub.execute_input":"2021-09-15T10:10:42.583616Z","iopub.status.idle":"2021-09-15T10:10:43.590113Z","shell.execute_reply.started":"2021-09-15T10:10:42.583567Z","shell.execute_reply":"2021-09-15T10:10:43.589461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n# 绘制混淆矩阵\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    Input\n    - cm : 计算出的混淆矩阵的值\n    - classes : 混淆矩阵中每一行每一列对应的列\n    - normalize : True:显示百分比, False:显示个数\n    \"\"\"\n    cm=cm.numpy()\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        cm=cm.astype('int')\n        print('Confusion matrix, without normalization')\n#     print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '{:.2f}' if normalize else '{}'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(i, j, fmt.format(cm[i, j]),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\n# 生成混淆矩阵\ndef confusion_matrix(preds, labels, conf_matrix):\n    preds = torch.argmax(preds, 1)\n    for p, t in zip(preds, labels):\n        conf_matrix[t, p] += 1\n    return conf_matrix\n\ndef calculate_all_prediction(conf_matrix):\n    '''\n    计算总精度：对角线上所有值除以总数\n    '''\n    total_sum = conf_matrix.sum()\n    correct_sum = (np.diag(conf_matrix)).sum()\n    prediction = round(100*float(correct_sum)/float(total_sum),2)\n    return prediction\n \ndef calculate_label_prediction(conf_matrix,labelidx):\n    '''\n    计算某一个类标预测精度：该类被预测正确的数除以该类的总数\n    '''\n    label_total_sum = conf_matrix.sum(axis=0)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    prediction = 0\n    if label_total_sum != 0:\n        prediction = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return prediction\n \ndef calculate_label_recall(conf_matrix,labelidx):\n    '''\n    计算某一个类标的召回率：\n    '''\n    label_total_sum = conf_matrix.sum(axis=1)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    recall = 0\n    if label_total_sum != 0:\n        recall = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return recall\n \ndef calculate_f1(prediction,recall):\n    if (prediction+recall)==0:\n        return 0\n    return round(2*prediction*recall/(prediction+recall),2)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:43.591547Z","iopub.execute_input":"2021-09-15T10:10:43.591786Z","iopub.status.idle":"2021-09-15T10:10:43.610083Z","shell.execute_reply.started":"2021-09-15T10:10:43.591754Z","shell.execute_reply":"2021-09-15T10:10:43.609087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RESNET_34_WoF(nn.Module):\n    def __init__(self, num_classes,pretrained=True):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=pretrained)\n        # Replace last layer\n        self.network.fc = nn.Linear(self.network.fc.in_features, num_classes)\n        for param in self.network.fc.parameters():\n          param.requires_grad = True\n          \n    def forward(self, xb):\n        return self.network(xb)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:43.611632Z","iopub.execute_input":"2021-09-15T10:10:43.611886Z","iopub.status.idle":"2021-09-15T10:10:43.618475Z","shell.execute_reply.started":"2021-09-15T10:10:43.611855Z","shell.execute_reply":"2021-09-15T10:10:43.617663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel=torch.load('../input/whole-model/k_cross_CNN.pt')\nmodel=model.to(device)\n# print(model)\n\n# model=models.vgg16(pretrained=True)\n# # 将所有参数都设置为不计算梯度\n# for param in model.parameters():\n#     param.requires_grad=False\n# num_ftrs=model.classifier[6].in_features # feature_map 的大小\n# model.classifier[6]=nn.Linear(num_ftrs,num_classes) #重新设计全连接层\n# model=model.to(device)\n\ncriterion=nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.0001,betas=(0.9, 0.999)) #优化函数\nnum_iter=(int(len(train_df)/batch_size))*num_epochs\nsched=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=num_iter,\n                                                     eta_min=0.00001)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:43.619557Z","iopub.execute_input":"2021-09-15T10:10:43.619933Z","iopub.status.idle":"2021-09-15T10:10:50.902813Z","shell.execute_reply.started":"2021-09-15T10:10:43.619896Z","shell.execute_reply":"2021-09-15T10:10:50.90201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,epoch,num_epochs,criterion,optimizer,sched):\n    model.train()\n    print('-' * 100)\n    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n    running_loss = 0.0\n    running_corrects = 0\n    for idx, (inputs, labels) in enumerate(dataloaders['train']):# 对dataloader进行遍历，dataloader时包含数据及标签的元组\n        inputs,labels=inputs.to(device),labels.to(device)\n        outputs = model(inputs) # output接受结果\n        _, preds = torch.max(outputs, 1)\n        loss = criterion(outputs, labels)  # 默认平均，计算损失值\n\n        #反向传播及更新\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        sched.step()\n\n#         if idx % 100 == 99:\n#             print('train iteration:{},loss:{},acc:{}%'.format( idx, loss.item(),torch.sum(preds == labels.data)/batch_size*100))\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\n    epoch_loss = running_loss / dataset_sizes['train']\n    epoch_acc = running_corrects.double() / dataset_sizes['train']\n    print('train_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:50.904043Z","iopub.execute_input":"2021-09-15T10:10:50.904322Z","iopub.status.idle":"2021-09-15T10:10:50.914811Z","shell.execute_reply.started":"2021-09-15T10:10:50.904289Z","shell.execute_reply":"2021-09-15T10:10:50.914116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model,epoch,num_epochs,criterion,optimizer,best_acc):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    best_acc=best_acc\n    best_model_wts=copy.deepcopy(model.state_dict())\n    conf_matrix = torch.zeros(num_classes, num_classes) # 混淆矩阵初始化\n    with torch.no_grad():\n        for idx, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)\n            conf_matrix = confusion_matrix(outputs, labels, conf_matrix) # 生成混淆矩阵\n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data) #preds是tensor,labels.data是tensor\n\n        plot_confusion_matrix(conf_matrix, classes=class_names, normalize=False, title='confusion matrix') # 混淆矩阵的可视化\n\n    epoch_loss = running_loss / dataset_sizes['val'] \n    epoch_acc = running_corrects.double() / dataset_sizes['val'] #type为tensor\n    print('val_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))\n\n    all_prediction = calculate_all_prediction(conf_matrix) # 总精度=准确率\n    print('all_prediction:{}'.format(all_prediction))\n    label_prediction = [] # 存放每个类的精确率\n    label_recall = [] # 存放每个类的召回率\n    for i in range(num_classes):\n        label_prediction.append(calculate_label_prediction(conf_matrix,i))\n        label_recall.append(calculate_label_recall(conf_matrix,i))\n\n    keys=class_names\n    values=list(range(num_classes))\n    dictionary = dict(zip(keys, values))\n    for ei,i in enumerate(dictionary):\n        print(ei,'\\t',i,'\\t','prediction=',label_prediction[ei],'%,\\trecall=',label_recall[ei],'%,\\tf1=',calculate_f1(label_prediction[ei],label_recall[ei])) # 输出每个类的，精确率，召回率，F1\n    p = round(np.array(label_prediction).sum()/len(label_prediction),2) # 总精确率\n    r = round(np.array(label_recall).sum()/len(label_prediction),2) # 总召回率\n    print('MACRO-averaged:\\nprediction=',p,'%,recall=',r,'%,f1=',calculate_f1(p,r)) #输出总精确率和召回率\n\n#     print(epoch_acc.tpye)\n#     print(best_acc.type)\n    if epoch_acc > best_acc:# 获取最好的模型和准确率\n        best_acc=epoch_acc.item()\n        best_model_wts=copy.deepcopy(model.state_dict())\n#     model.load_state_dict(best_model_wts)\n\n    return best_model_wts,best_acc,epoch_acc.item()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:50.917693Z","iopub.execute_input":"2021-09-15T10:10:50.917895Z","iopub.status.idle":"2021-09-15T10:10:50.933743Z","shell.execute_reply.started":"2021-09-15T10:10:50.917863Z","shell.execute_reply":"2021-09-15T10:10:50.933029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    acc=[]\n    for epoch in range(num_epochs):\n        train(model,epoch,num_epochs,criterion,optimizer,sched)\n        best_model_wts,best_acc,epoch_acc=test(model,epoch,num_epochs,criterion,optimizer,best_acc)\n        acc.append(epoch_acc)\n    print('*' * 100)\n    print('best_acc:{}'.format(best_acc))\n    print('*' * 100)\n    torch.save(best_model_wts, 'resnet34_wof.pth')","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:10:50.936444Z","iopub.execute_input":"2021-09-15T10:10:50.936656Z","iopub.status.idle":"2021-09-15T10:11:07.314444Z","shell.execute_reply.started":"2021-09-15T10:10:50.936627Z","shell.execute_reply":"2021-09-15T10:11:07.312383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_,_,acc=test(model,1,20,criterion,optimizer,best_acc)\nprint(\"Resnet 34 WoF on COVIDXCT dataset Accuray: \",acc)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T10:11:07.315773Z","iopub.status.idle":"2021-09-15T10:11:07.316201Z","shell.execute_reply.started":"2021-09-15T10:11:07.315951Z","shell.execute_reply":"2021-09-15T10:11:07.315973Z"},"trusted":true},"execution_count":null,"outputs":[]}]}